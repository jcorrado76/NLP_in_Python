{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we build a recurrent neural network with a single layer, consisting of a single neuron with PyTorch.\n",
    "\n",
    "Import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with a Single Neuron\n",
    "***\n",
    "Here is the implementation of a simple one layer, single neuron RNN. We have initialized two weight matrices, `Wx` and `Wy` with values from a normal distribution. `Wx` contains connection weights for the inputs of the previous time step. `Wy` contains connection weights for the outputs of the previous time step. The `forward` function computes two outputs - one for each time step. \n",
    "\n",
    "<img src=\"img/RNN_pic_1.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SingleRNN(nn.Module):\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super(SingleRNN, self).__init__()\n",
    "        self.Wx = torch.randn(n_inputs, n_neurons)  # 4x1\n",
    "        self.Wy = torch.randn(n_neurons, n_neurons) # 1x1\n",
    "        self.b = torch.zeros(1, n_neurons)          # 1x4\n",
    "    def forward(self, X0, X1):\n",
    "        self.Y0 = torch.tanh(torch.mm(X0, self.Wx) + self.b) # 4x1\n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) + torch.mm(X1, self.Wx) +self.b) # 4x1\n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/single_layer_RNN_architecture.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />\n",
    "\n",
    "For the input, we use 4 instances, with each instance containing two input sequences. \n",
    "\n",
    "Here is an example for the usage of the model:\n",
    "\n",
    "<img src=\"img/data_feed_into_RNN.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_batch = torch.tensor([[0,1,2,0], [3,4,5,0],\\\n",
    "                        [6,7,8,0],[9,0,1,0]],\\\n",
    "                       dtype=torch.float) # t=0 -> 4x4\n",
    "X1_batch = torch.tensor([[9,8,7,0],[0,0,0,0],\\\n",
    "                        [6,5,4,0],[3,2,1,0]],\\\n",
    "                       dtype=torch.float) # t=1 -> 4x4\n",
    "\n",
    "N_INPUT = 4\n",
    "N_NEURONS = 1\n",
    "model = SingleRNN(N_INPUT, N_NEURONS)\n",
    "\n",
    "Y0_val, Y1_val = model(X0_batch, X1_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will result in outputs for each timestep `Y0` and `Y1`, each of size 4x1, which represent the size of batch and hidden units, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5996],\n",
      "        [0.9998],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "tensor([[ 1.0000],\n",
      "        [-0.8045],\n",
      "        [ 1.0000],\n",
      "        [ 0.9758]])\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with Multiple Neurons\n",
    "***\n",
    "Now we can increase the number of neurons in the RNN layer. Since we already had left `n_inputs` and `n_neurons` as variables to be passed into the constructor, we don't have to change anything about our class except for the name.\n",
    "\n",
    "<img src=\"img/simple_RNN_n_neurons.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super(SingleRNN, self).__init__()\n",
    "        self.Wx = torch.randn(n_inputs, n_neurons)  # n_inputs x n_neurons\n",
    "        self.Wy = torch.randn(n_neurons, n_neurons) # n_neurons x n_neurons\n",
    "        self.b = torch.zeros(1, n_neurons)          # 1 x n_neurons\n",
    "    def forward(self, X0, X1):\n",
    "        self.Y0 = torch.tanh(torch.mm(X0, self.Wx) + self.b) # batch_size x n_neurons\n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) + torch.mm(X1, self.Wx) +self.b) # batch_size x n_neurons\n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 3 # number of features in input\n",
    "N_NEURONS = 5 # number of units in layer\n",
    "\n",
    "X0_batch = torch.tensor([[0,1,2], [3,4,5],[6,7,8], [9,0,1]],dtype=torch.float) # t=0 -> 4x3\n",
    "X1_batch = torch.tensor([[9,8,7], [0,0,0], [6,5,4], [3,2,1]], dtype=torch.float) # t=1 -> 4x3\n",
    "\n",
    "model = SingleRNN(N_INPUT, N_NEURONS)\n",
    "\n",
    "Y0_val, Y1_val = model(X0_batch, X1_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8361,  0.4522,  0.9692, -0.0313, -0.4367],\n",
      "        [ 0.3682, -0.6885,  0.9996, -0.7780,  0.7924],\n",
      "        [ 0.9626, -0.9746,  1.0000, -0.9673,  0.9895],\n",
      "        [ 0.9753, -1.0000, -1.0000, -0.9998,  1.0000]])\n",
      "tensor([[ 1.0000, -0.9103,  1.0000, -0.9978,  1.0000],\n",
      "        [ 0.0450,  0.4532,  0.6085,  0.8330, -0.9481],\n",
      "        [ 0.9992, -0.9964,  0.9739, -0.3256,  0.5406],\n",
      "        [ 0.9995, -1.0000, -0.9988,  0.3133, -0.9926]])\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Built-in RNN Cell\n",
    "***\n",
    "The way we have implemented our RNN above means that if we wanted to build an architecture that supports extremely large inputs and outputs, we would have to individually compute the outputs for every time step, increasing the liens of code needed to implement the desired computation graph. \n",
    "\n",
    "Instead, we can consolidate and implement this RNN architecture more efficiently and cleanly using the built in `RNNCell` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.6990, -0.7297, -0.8801,  0.1854, -0.5004],\n",
      "        [-0.9443, -0.9051, -0.5188,  0.9710,  0.9781],\n",
      "        [-0.9989, -0.9988, -0.9422,  0.9994,  0.9997],\n",
      "        [-0.2015, -0.9980,  0.8230,  0.7355,  0.6869]], grad_fn=<TanhBackward>), tensor([[-0.9923, -0.9990,  0.1942,  0.9999,  0.9998],\n",
      "        [-0.1589,  0.2251, -0.0162, -0.5187, -0.9219],\n",
      "        [-0.9569, -0.9754,  0.2113,  0.9927,  0.9418],\n",
      "        [-0.7972, -0.9371,  0.0641,  0.5208, -0.0497]], grad_fn=<TanhBackward>)]\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNNCell(3,5) # n_inputs x n_neurons\n",
    "\n",
    "X_batch = torch.tensor([[[0,1,2], [3,4,5], \\\n",
    "                         [6,7,8], [9,0,2]], \\\n",
    "                        [[9,8,7], [0,0,0], \\\n",
    "                         [6,5,4], [3,2,1]]], dtype=torch.float)\n",
    "\n",
    "hx = torch.randn(4,5) # m x n_neurons\n",
    "output = []\n",
    "\n",
    "# for each time step\n",
    "for i in range(2):\n",
    "    hx = rnn(X_batch[i], hx)\n",
    "    output.append(hx)\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is the same model as we implemented from scratch in BasicRNN, except now we  don't have to deal individually with the weights and biases, and that is abstracted away for us. So now we can rewrite our class as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CleanBasicRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_inputs, n_neurons):\n",
    "        super(CleanBasicRNN, self).__init__()\n",
    "        rnn = nn.RNNCell(n_inputs, n_neurons)\n",
    "        self.hx = torch.randn(batch_size, n_neurons)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        \n",
    "        for i in range(2):\n",
    "            self.hx = rnn(x[i], self.hx)\n",
    "            output.append(self.hx)\n",
    "            \n",
    "        return output, self.hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.8465, -0.2058, -0.6323,  0.1341,  0.0972],\n",
      "        [-0.9175, -0.9723, -0.0428,  0.9554,  0.9582],\n",
      "        [-0.9939, -0.9956, -0.6253,  0.9971,  0.9984],\n",
      "        [ 0.5503, -0.9983,  0.5700,  0.9839,  0.8755]], grad_fn=<TanhBackward>), tensor([[-0.9966, -0.9989, -0.1796,  0.9999,  0.9998],\n",
      "        [-0.3029,  0.0358, -0.0608, -0.6554, -0.9200],\n",
      "        [-0.9664, -0.9807,  0.1707,  0.9905,  0.9439],\n",
      "        [-0.7852, -0.9447, -0.0751,  0.7677, -0.1597]], grad_fn=<TanhBackward>)]\n",
      "tensor([[-0.9966, -0.9989, -0.1796,  0.9999,  0.9998],\n",
      "        [-0.3029,  0.0358, -0.0608, -0.6554, -0.9200],\n",
      "        [-0.9664, -0.9807,  0.1707,  0.9905,  0.9439],\n",
      "        [-0.7852, -0.9447, -0.0751,  0.7677, -0.1597]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "FIXED_BATCH_SIZE = 4\n",
    "N_INPUT = 3\n",
    "N_NEURONS = 5\n",
    "\n",
    "X0 = [[0,1,2], [3,4,5],\\\n",
    "      [6,7,8], [9,0,1]]\n",
    "X1 = [[9,8,7], [0,0,0],\\\n",
    "      [6,5,4], [3,2,1]]\n",
    "\n",
    "x_batch = torch.tensor([X0, X1], dtype=torch.float) # X0 and X1\n",
    "\n",
    "model = CleanBasicRNN(FIXED_BATCH_SIZE, N_INPUT, N_NEURONS)\n",
    "output_val, states_val = model(x_batch)\n",
    "print(output_val) # all output for all timesteps\n",
    "print(states_val) # values for final state or final timestep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN For MNIST Image Classification\n",
    "***\n",
    "Here are the parameters for the computation graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 28\n",
    "N_INPUTS = 28\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 10\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we show how to load and import the data using PyTorch libraries.\n",
    "\n",
    "This code loads and prepares the dataset to be fed into the computation graph that we will build. We needed to provide a `BATCH_SIZE` because `trainloader` and `testloader` are iterators that make it easier when we are iterating over the dataset and training our RNN model with minibatches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# list the transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(ImageRNN, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        # declare a basic RNN layer\n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons)\n",
    "        # followed by a fully-connected layer\n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        \"\"\"\n",
    "        initializes hidden weights with zero values\n",
    "        \"\"\"\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        run data through the RNN layer and then through the fully-connected layer\n",
    "        outputs the log probabilities of the model because of softmax\n",
    "        \"\"\"\n",
    "        # transform x into shape: (n_steps x batch_size x n_inputs)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        self.batch_size = x.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        lstm_out, self.hidden = self.basic_rnn(x, self.hidden)\n",
    "        \n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out.view(-1, self.n_outputs) # (batch_size x n_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model with some samples\n",
    "***\n",
    "always test the model with a portion of the dataset before actual training. this is to ensure you have the correct dimensions specified and that the model is producing the information you expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0043, -0.1175,  0.0033, -0.0574, -0.0428,  0.0006,  0.0652, -0.0544,\n",
      "         -0.0246, -0.0275],\n",
      "        [-0.0187, -0.1309,  0.0095, -0.0603, -0.0512, -0.0056,  0.0719, -0.0444,\n",
      "         -0.0294, -0.0033],\n",
      "        [-0.0247, -0.1163, -0.0299, -0.0107, -0.0474, -0.0410,  0.0526, -0.0251,\n",
      "         -0.0371, -0.0429],\n",
      "        [-0.0109, -0.1150,  0.0015, -0.0586, -0.0421,  0.0002,  0.0617, -0.0536,\n",
      "         -0.0239, -0.0301],\n",
      "        [-0.0191, -0.1034, -0.0041, -0.0528, -0.0347, -0.0087,  0.0613, -0.0399,\n",
      "         -0.0170, -0.0231],\n",
      "        [-0.0055, -0.1216,  0.0005, -0.0496, -0.0299, -0.0015,  0.0612, -0.0459,\n",
      "         -0.0222, -0.0230],\n",
      "        [-0.0073, -0.1224,  0.0066, -0.0565, -0.0351,  0.0015,  0.0622, -0.0465,\n",
      "         -0.0198, -0.0280],\n",
      "        [-0.0128, -0.1174,  0.0104, -0.0594, -0.0425, -0.0050,  0.0639, -0.0501,\n",
      "         -0.0189, -0.0249],\n",
      "        [-0.0183, -0.1140,  0.0057, -0.0601, -0.0526, -0.0087,  0.0644, -0.0419,\n",
      "         -0.0236, -0.0207],\n",
      "        [-0.0060, -0.1198, -0.0006, -0.0610, -0.0392, -0.0044,  0.0602, -0.0551,\n",
      "         -0.0305, -0.0346]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "logits = model(images.view(-1, 28, 28))\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "***\n",
    "Before training a model in PyTorch, programatically specify what device you want to use during training. \n",
    "\n",
    "Then, create and instance of `ImageRNN` with the proper parameters. `criterion` specifies the loss function we are using. `nn.CrossEntropyLoss()` applies a log softmax followed by negative log likelihood loss operation over the output of the model. In order to compute this loss, the function needs the log probabilities outputted by our model and the target labels.\n",
    "\n",
    "In addition, we use an optimization algorithm in order to update the weights based on current loss. This is done through `optim.Adam` optimization function. This function requires the model parameters and the learning rate. \n",
    "\n",
    "You could alternatively use `optim.SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects / batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.2320 | Train Accuracy: 92.99\n",
      "Epoch: 1 | Loss: 0.2014 | Train Accuracy: 93.90\n",
      "Epoch: 2 | Loss: 0.1712 | Train Accuracy: 94.74\n",
      "Epoch: 3 | Loss: 0.1547 | Train Accuracy: 95.24\n",
      "Epoch: 4 | Loss: 0.1436 | Train Accuracy: 95.58\n",
      "Epoch: 5 | Loss: 0.1310 | Train Accuracy: 95.92\n",
      "Epoch: 6 | Loss: 0.1268 | Train Accuracy: 96.04\n",
      "Epoch: 7 | Loss: 0.1241 | Train Accuracy: 96.09\n",
      "Epoch: 8 | Loss: 0.1151 | Train Accuracy: 96.27\n",
      "Epoch: 9 | Loss: 0.1108 | Train Accuracy: 96.47\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden()\n",
    "        # get inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1,28,28)\n",
    "        \n",
    "        #forward + backward + optimze\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "    model.eval()\n",
    "    print(\"Epoch: {0:d} | Loss: {1:.4f} | Train Accuracy: {2:.2f}\".\\\n",
    "          format(epoch, train_running_loss / i, train_acc / i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the accuracy on the test set to see how well our model generalizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.13\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1,28,28)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "\n",
    "print(\"Test Accuracy: {0:.2f}\".format(test_acc / i))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
