{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "***\n",
    "When using Word2Vec, you're making the assumption of the distributional hypothesis: **the meaning of a word can be inferred by the company it keeps**. \n",
    "\n",
    "In this sense, if you have two words with very similar neighbors, then these words are probably similar in meaning. \n",
    "\n",
    "In this tutorial, we will use the Gensim implementation of Word2Vec and we will get it working. \n",
    "\n",
    "For this tutorial, we will use data from the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/#.XUkA6nVKhhE) dataset. This dataset has car and hotel reviews. We will compress the hotel reviews into a single file and use them for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import logging\n",
    "import gensim\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\",\\\n",
    "                   level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "***\n",
    "THe secret to getting Word2Vec working for you is to have lots of text data relevant to the task at hand. In this case we will be using a hotel reviews dataset. \n",
    "\n",
    "The total file is about 228MB in size. \n",
    "\n",
    "You can pass a sequence of sentences to gensim as input, so we can pass a whole review as a sentence (a large chunk of text). \n",
    "\n",
    "We will read the data into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"data/hotel_reviews.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gensim.utils.simple_preprocess` performs tokenization, lowercasing and returns a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def read_input(file_path):\n",
    "    \"\"\"\n",
    "    Read the input file\n",
    "    \"\"\"\n",
    "    logging.info(\"reading file {}...this may take a while\".format(file_path))\n",
    "    \n",
    "    with gzip.open(file_path, 'rb') as filehandle:\n",
    "        for i, line in enumerate(filehandle):\n",
    "            if (i%10000==0):\n",
    "                logging.info(\"read {} reviews\".format(i))\n",
    "            # do some preprocessing and return list of tokens (list of strings) for each review\n",
    "            yield gensim.utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a list of lists. Each element of this list is a list of tokens from that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-10 23:21:16,971 : INFO : reading file data/hotel_reviews.tgz...this may take a while\n",
      "2019-08-10 23:21:16,973 : INFO : read 0 reviews\n",
      "2019-08-10 23:21:17,772 : INFO : read 10000 reviews\n",
      "2019-08-10 23:21:18,608 : INFO : read 20000 reviews\n",
      "2019-08-10 23:21:19,438 : INFO : read 30000 reviews\n",
      "2019-08-10 23:21:20,272 : INFO : read 40000 reviews\n",
      "2019-08-10 23:21:21,113 : INFO : read 50000 reviews\n",
      "2019-08-10 23:21:22,010 : INFO : read 60000 reviews\n",
      "2019-08-10 23:21:22,870 : INFO : read 70000 reviews\n",
      "2019-08-10 23:21:23,723 : INFO : read 80000 reviews\n",
      "2019-08-10 23:21:24,552 : INFO : read 90000 reviews\n",
      "2019-08-10 23:21:25,401 : INFO : read 100000 reviews\n",
      "2019-08-10 23:21:26,238 : INFO : read 110000 reviews\n",
      "2019-08-10 23:21:27,101 : INFO : read 120000 reviews\n",
      "2019-08-10 23:21:27,951 : INFO : read 130000 reviews\n",
      "2019-08-10 23:21:28,797 : INFO : read 140000 reviews\n",
      "2019-08-10 23:21:29,814 : INFO : read 150000 reviews\n",
      "2019-08-10 23:21:30,643 : INFO : read 160000 reviews\n",
      "2019-08-10 23:21:31,447 : INFO : read 170000 reviews\n",
      "2019-08-10 23:21:32,281 : INFO : read 180000 reviews\n",
      "2019-08-10 23:21:33,125 : INFO : read 190000 reviews\n",
      "2019-08-10 23:21:33,964 : INFO : read 200000 reviews\n",
      "2019-08-10 23:21:34,810 : INFO : read 210000 reviews\n",
      "2019-08-10 23:21:35,652 : INFO : read 220000 reviews\n",
      "2019-08-10 23:21:36,481 : INFO : read 230000 reviews\n",
      "2019-08-10 23:21:37,604 : INFO : read 240000 reviews\n",
      "2019-08-10 23:21:38,451 : INFO : read 250000 reviews\n",
      "2019-08-10 23:21:39,293 : INFO : read 260000 reviews\n",
      "2019-08-10 23:21:40,138 : INFO : read 270000 reviews\n",
      "2019-08-10 23:21:40,978 : INFO : read 280000 reviews\n",
      "2019-08-10 23:21:41,799 : INFO : read 290000 reviews\n",
      "2019-08-10 23:21:42,616 : INFO : read 300000 reviews\n",
      "2019-08-10 23:21:43,449 : INFO : read 310000 reviews\n",
      "2019-08-10 23:21:44,289 : INFO : read 320000 reviews\n",
      "2019-08-10 23:21:45,487 : INFO : read 330000 reviews\n",
      "2019-08-10 23:21:46,326 : INFO : read 340000 reviews\n",
      "2019-08-10 23:21:47,181 : INFO : read 350000 reviews\n",
      "2019-08-10 23:21:48,059 : INFO : read 360000 reviews\n",
      "2019-08-10 23:21:48,892 : INFO : read 370000 reviews\n",
      "2019-08-10 23:21:49,704 : INFO : read 380000 reviews\n",
      "2019-08-10 23:21:50,526 : INFO : read 390000 reviews\n",
      "2019-08-10 23:21:51,363 : INFO : read 400000 reviews\n",
      "2019-08-10 23:21:52,167 : INFO : read 410000 reviews\n",
      "2019-08-10 23:21:53,038 : INFO : read 420000 reviews\n",
      "2019-08-10 23:21:53,870 : INFO : read 430000 reviews\n",
      "2019-08-10 23:21:55,160 : INFO : read 440000 reviews\n",
      "2019-08-10 23:21:55,986 : INFO : read 450000 reviews\n",
      "2019-08-10 23:21:56,828 : INFO : read 460000 reviews\n",
      "2019-08-10 23:21:57,641 : INFO : read 470000 reviews\n",
      "2019-08-10 23:21:58,450 : INFO : read 480000 reviews\n",
      "2019-08-10 23:21:59,256 : INFO : read 490000 reviews\n",
      "2019-08-10 23:22:00,069 : INFO : read 500000 reviews\n",
      "2019-08-10 23:22:00,934 : INFO : read 510000 reviews\n",
      "2019-08-10 23:22:01,399 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "documents = list(read_input(data_file))\n",
    "logging.info(\"Done reading data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "['hotel_reviews', 'csv', 'ustar', 'joseph', 'joseph', 'hotel_address', 'review_date', 'average_score', 'hotel_name', 'negative_review', 'positive_review', 'reviewer_score', 'tags', 'lat', 'lng']\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))\n",
    "print(type(documents[0]))\n",
    "print(documents[0])\n",
    "print(type(documents[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Word2Vec Model\n",
    "***\n",
    "Now we train the Word2Vec model. To gensim for this, we simple instantiate Word2Vec and pass the list of reviews we just read. \n",
    "\n",
    "Word2Vec will use this list of lists to create an internal vocabulary.\n",
    "\n",
    "After building the vocabulary, we call `train(...)` to train the Word2Vec model. \n",
    "\n",
    "We train on the OpinRank dataset, which should take around 10 minutes. \n",
    "This is training a neural network with a single hidden layer. For the word vectors, we do not use the actual resulting neural network as a model, but we take the weights from the hidden layer. These are essentially the word vectors that we're trying to learn\n",
    "## Parameters\n",
    "***\n",
    "The constructor for our `Word2Vec` model take some parameters:\n",
    "```python\n",
    "model = gensim.models.Word2Vec(documents, size=150, window=10, min_count=2, workers=8)\n",
    "```\n",
    "* **size** - size of the dense vector to represent each token or word. if you have few data, choose a smaller size.\n",
    "* **window** - the maximum distance between a target word and its neighboring context word\n",
    "* **min_count** - minimum frequency count of words. ignore words that don't satisfy the word count. infrequent words are usually unimportant so this removes those\n",
    "* **workers** - number of threads to use on the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 17:34:02,739 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-08-06 17:34:02,740 : INFO : collecting all words and their counts\n",
      "2019-08-06 17:34:02,741 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-08-06 17:34:02,848 : INFO : PROGRESS: at sentence #10000, processed 631538 words, keeping 10659 word types\n",
      "2019-08-06 17:34:02,932 : INFO : PROGRESS: at sentence #20000, processed 1188643 words, keeping 14156 word types\n",
      "2019-08-06 17:34:03,021 : INFO : PROGRESS: at sentence #30000, processed 1772531 words, keeping 17164 word types\n",
      "2019-08-06 17:34:03,110 : INFO : PROGRESS: at sentence #40000, processed 2362096 words, keeping 19706 word types\n",
      "2019-08-06 17:34:03,199 : INFO : PROGRESS: at sentence #50000, processed 2946890 words, keeping 21949 word types\n",
      "2019-08-06 17:34:03,287 : INFO : PROGRESS: at sentence #60000, processed 3522800 words, keeping 23966 word types\n",
      "2019-08-06 17:34:03,381 : INFO : PROGRESS: at sentence #70000, processed 4121671 words, keeping 26098 word types\n",
      "2019-08-06 17:34:03,473 : INFO : PROGRESS: at sentence #80000, processed 4712124 words, keeping 27765 word types\n",
      "2019-08-06 17:34:03,562 : INFO : PROGRESS: at sentence #90000, processed 5288703 words, keeping 29373 word types\n",
      "2019-08-06 17:34:03,655 : INFO : PROGRESS: at sentence #100000, processed 5879882 words, keeping 31074 word types\n",
      "2019-08-06 17:34:03,749 : INFO : PROGRESS: at sentence #110000, processed 6465646 words, keeping 32688 word types\n",
      "2019-08-06 17:34:03,852 : INFO : PROGRESS: at sentence #120000, processed 7063911 words, keeping 34314 word types\n",
      "2019-08-06 17:34:03,946 : INFO : PROGRESS: at sentence #130000, processed 7658760 words, keeping 35634 word types\n",
      "2019-08-06 17:34:04,039 : INFO : PROGRESS: at sentence #140000, processed 8255438 words, keeping 36971 word types\n",
      "2019-08-06 17:34:04,130 : INFO : PROGRESS: at sentence #150000, processed 8849289 words, keeping 38256 word types\n",
      "2019-08-06 17:34:04,219 : INFO : PROGRESS: at sentence #160000, processed 9419819 words, keeping 39542 word types\n",
      "2019-08-06 17:34:04,307 : INFO : PROGRESS: at sentence #170000, processed 9984558 words, keeping 40635 word types\n",
      "2019-08-06 17:34:04,398 : INFO : PROGRESS: at sentence #180000, processed 10567250 words, keeping 41824 word types\n",
      "2019-08-06 17:34:04,489 : INFO : PROGRESS: at sentence #190000, processed 11160323 words, keeping 42987 word types\n",
      "2019-08-06 17:34:04,582 : INFO : PROGRESS: at sentence #200000, processed 11750047 words, keeping 44080 word types\n",
      "2019-08-06 17:34:04,674 : INFO : PROGRESS: at sentence #210000, processed 12340898 words, keeping 45295 word types\n",
      "2019-08-06 17:34:04,768 : INFO : PROGRESS: at sentence #220000, processed 12931391 words, keeping 46367 word types\n",
      "2019-08-06 17:34:04,862 : INFO : PROGRESS: at sentence #230000, processed 13515110 words, keeping 47484 word types\n",
      "2019-08-06 17:34:04,960 : INFO : PROGRESS: at sentence #240000, processed 14115597 words, keeping 48362 word types\n",
      "2019-08-06 17:34:05,051 : INFO : PROGRESS: at sentence #250000, processed 14705780 words, keeping 49429 word types\n",
      "2019-08-06 17:34:05,142 : INFO : PROGRESS: at sentence #260000, processed 15291098 words, keeping 50441 word types\n",
      "2019-08-06 17:34:05,233 : INFO : PROGRESS: at sentence #270000, processed 15876266 words, keeping 51512 word types\n",
      "2019-08-06 17:34:05,325 : INFO : PROGRESS: at sentence #280000, processed 16463973 words, keeping 52937 word types\n",
      "2019-08-06 17:34:05,415 : INFO : PROGRESS: at sentence #290000, processed 17032693 words, keeping 54060 word types\n",
      "2019-08-06 17:34:05,507 : INFO : PROGRESS: at sentence #300000, processed 17604761 words, keeping 55225 word types\n",
      "2019-08-06 17:34:05,595 : INFO : PROGRESS: at sentence #310000, processed 18175692 words, keeping 56399 word types\n",
      "2019-08-06 17:34:05,686 : INFO : PROGRESS: at sentence #320000, processed 18756620 words, keeping 57581 word types\n",
      "2019-08-06 17:34:05,782 : INFO : PROGRESS: at sentence #330000, processed 19342989 words, keeping 58630 word types\n",
      "2019-08-06 17:34:05,872 : INFO : PROGRESS: at sentence #340000, processed 19923964 words, keeping 59842 word types\n",
      "2019-08-06 17:34:05,965 : INFO : PROGRESS: at sentence #350000, processed 20503054 words, keeping 60947 word types\n",
      "2019-08-06 17:34:06,056 : INFO : PROGRESS: at sentence #360000, processed 21069964 words, keeping 62026 word types\n",
      "2019-08-06 17:34:06,145 : INFO : PROGRESS: at sentence #370000, processed 21642447 words, keeping 62991 word types\n",
      "2019-08-06 17:34:06,234 : INFO : PROGRESS: at sentence #380000, processed 22207630 words, keeping 64199 word types\n",
      "2019-08-06 17:34:06,324 : INFO : PROGRESS: at sentence #390000, processed 22783424 words, keeping 65140 word types\n",
      "2019-08-06 17:34:06,416 : INFO : PROGRESS: at sentence #400000, processed 23370794 words, keeping 66208 word types\n",
      "2019-08-06 17:34:06,504 : INFO : PROGRESS: at sentence #410000, processed 23927037 words, keeping 67229 word types\n",
      "2019-08-06 17:34:06,600 : INFO : PROGRESS: at sentence #420000, processed 24539393 words, keeping 68309 word types\n",
      "2019-08-06 17:34:06,690 : INFO : PROGRESS: at sentence #430000, processed 25109468 words, keeping 69229 word types\n",
      "2019-08-06 17:34:06,783 : INFO : PROGRESS: at sentence #440000, processed 25685613 words, keeping 70117 word types\n",
      "2019-08-06 17:34:06,877 : INFO : PROGRESS: at sentence #450000, processed 26255505 words, keeping 71116 word types\n",
      "2019-08-06 17:34:06,972 : INFO : PROGRESS: at sentence #460000, processed 26845443 words, keeping 71911 word types\n",
      "2019-08-06 17:34:07,061 : INFO : PROGRESS: at sentence #470000, processed 27405841 words, keeping 72786 word types\n",
      "2019-08-06 17:34:07,149 : INFO : PROGRESS: at sentence #480000, processed 27965252 words, keeping 73847 word types\n",
      "2019-08-06 17:34:07,239 : INFO : PROGRESS: at sentence #490000, processed 28534382 words, keeping 75001 word types\n",
      "2019-08-06 17:34:07,327 : INFO : PROGRESS: at sentence #500000, processed 29097390 words, keeping 75989 word types\n",
      "2019-08-06 17:34:07,423 : INFO : PROGRESS: at sentence #510000, processed 29712245 words, keeping 76928 word types\n",
      "2019-08-06 17:34:07,474 : INFO : collected 77418 word types from a corpus of 30031149 raw words and 515740 sentences\n",
      "2019-08-06 17:34:07,475 : INFO : Loading a fresh vocabulary\n",
      "2019-08-06 17:34:07,552 : INFO : min_count=2 retains 38014 unique words (49% of original 77418, drops 39404)\n",
      "2019-08-06 17:34:07,552 : INFO : min_count=2 leaves 29991745 word corpus (99% of original 30031149, drops 39404)\n",
      "2019-08-06 17:34:07,648 : INFO : deleting the raw counts dictionary of 77418 items\n",
      "2019-08-06 17:34:07,651 : INFO : sample=0.001 downsamples 64 most-common words\n",
      "2019-08-06 17:34:07,652 : INFO : downsampling leaves estimated 21369631 word corpus (71.3% of prior 29991745)\n",
      "2019-08-06 17:34:07,767 : INFO : estimated required memory for 38014 words and 150 dimensions: 64623800 bytes\n",
      "2019-08-06 17:34:07,768 : INFO : resetting layer weights\n",
      "2019-08-06 17:34:08,170 : INFO : training model with 8 workers on 38014 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-08-06 17:34:09,177 : INFO : EPOCH 1 - PROGRESS: at 6.93% examples, 1476618 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:10,183 : INFO : EPOCH 1 - PROGRESS: at 14.22% examples, 1505884 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:34:11,185 : INFO : EPOCH 1 - PROGRESS: at 21.25% examples, 1509381 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:34:12,185 : INFO : EPOCH 1 - PROGRESS: at 28.11% examples, 1502566 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:13,186 : INFO : EPOCH 1 - PROGRESS: at 35.38% examples, 1508004 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:14,188 : INFO : EPOCH 1 - PROGRESS: at 42.51% examples, 1510993 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:15,195 : INFO : EPOCH 1 - PROGRESS: at 49.77% examples, 1514512 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:16,198 : INFO : EPOCH 1 - PROGRESS: at 56.92% examples, 1517911 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:17,205 : INFO : EPOCH 1 - PROGRESS: at 64.01% examples, 1516446 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:18,209 : INFO : EPOCH 1 - PROGRESS: at 71.33% examples, 1518817 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 17:34:19,215 : INFO : EPOCH 1 - PROGRESS: at 78.44% examples, 1517304 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:20,219 : INFO : EPOCH 1 - PROGRESS: at 85.49% examples, 1518734 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:21,226 : INFO : EPOCH 1 - PROGRESS: at 92.91% examples, 1520712 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:22,171 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:34:22,173 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:34:22,174 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:34:22,176 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:34:22,181 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:34:22,185 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:34:22,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:34:22,193 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:34:22,193 : INFO : EPOCH - 1 : training on 30031149 raw words (21369481 effective words) took 14.0s, 1524572 effective words/s\n",
      "2019-08-06 17:34:23,199 : INFO : EPOCH 2 - PROGRESS: at 7.09% examples, 1511884 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:24,202 : INFO : EPOCH 2 - PROGRESS: at 14.33% examples, 1517777 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:25,204 : INFO : EPOCH 2 - PROGRESS: at 21.53% examples, 1528824 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:26,205 : INFO : EPOCH 2 - PROGRESS: at 28.45% examples, 1520130 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:27,210 : INFO : EPOCH 2 - PROGRESS: at 35.78% examples, 1525433 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:34:28,213 : INFO : EPOCH 2 - PROGRESS: at 43.00% examples, 1526628 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:34:29,218 : INFO : EPOCH 2 - PROGRESS: at 49.85% examples, 1516993 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:30,221 : INFO : EPOCH 2 - PROGRESS: at 56.96% examples, 1519306 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:31,222 : INFO : EPOCH 2 - PROGRESS: at 64.26% examples, 1522605 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:32,229 : INFO : EPOCH 2 - PROGRESS: at 71.57% examples, 1523946 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:33,230 : INFO : EPOCH 2 - PROGRESS: at 78.52% examples, 1520107 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:34,234 : INFO : EPOCH 2 - PROGRESS: at 85.66% examples, 1523514 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:34:35,236 : INFO : EPOCH 2 - PROGRESS: at 93.19% examples, 1526344 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:34:36,158 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:34:36,160 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:34:36,162 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:34:36,166 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:34:36,169 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:34:36,172 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:34:36,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:34:36,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:34:36,183 : INFO : EPOCH - 2 : training on 30031149 raw words (21366789 effective words) took 14.0s, 1527867 effective words/s\n",
      "2019-08-06 17:34:37,201 : INFO : EPOCH 3 - PROGRESS: at 6.89% examples, 1449618 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:34:38,204 : INFO : EPOCH 3 - PROGRESS: at 14.03% examples, 1477425 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:39,214 : INFO : EPOCH 3 - PROGRESS: at 21.32% examples, 1504587 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:40,216 : INFO : EPOCH 3 - PROGRESS: at 28.56% examples, 1516968 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:41,221 : INFO : EPOCH 3 - PROGRESS: at 35.69% examples, 1516280 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:42,221 : INFO : EPOCH 3 - PROGRESS: at 43.05% examples, 1524402 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:43,225 : INFO : EPOCH 3 - PROGRESS: at 50.10% examples, 1521450 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:44,229 : INFO : EPOCH 3 - PROGRESS: at 57.48% examples, 1529102 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:45,230 : INFO : EPOCH 3 - PROGRESS: at 64.66% examples, 1530990 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:46,236 : INFO : EPOCH 3 - PROGRESS: at 72.13% examples, 1533372 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:34:47,244 : INFO : EPOCH 3 - PROGRESS: at 79.52% examples, 1536059 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:34:48,250 : INFO : EPOCH 3 - PROGRESS: at 86.63% examples, 1535854 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:34:49,251 : INFO : EPOCH 3 - PROGRESS: at 94.00% examples, 1536389 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:50,072 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:34:50,074 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:34:50,075 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:34:50,077 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:34:50,082 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:34:50,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:34:50,093 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:34:50,096 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:34:50,097 : INFO : EPOCH - 3 : training on 30031149 raw words (21367747 effective words) took 13.9s, 1536335 effective words/s\n",
      "2019-08-06 17:34:51,104 : INFO : EPOCH 4 - PROGRESS: at 7.09% examples, 1509814 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:52,111 : INFO : EPOCH 4 - PROGRESS: at 14.44% examples, 1528071 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:34:53,116 : INFO : EPOCH 4 - PROGRESS: at 21.63% examples, 1531679 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:54,117 : INFO : EPOCH 4 - PROGRESS: at 28.75% examples, 1532624 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:55,122 : INFO : EPOCH 4 - PROGRESS: at 36.04% examples, 1532801 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:56,124 : INFO : EPOCH 4 - PROGRESS: at 43.17% examples, 1532022 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:57,127 : INFO : EPOCH 4 - PROGRESS: at 50.41% examples, 1533476 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:34:58,131 : INFO : EPOCH 4 - PROGRESS: at 57.37% examples, 1528015 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:34:59,138 : INFO : EPOCH 4 - PROGRESS: at 64.66% examples, 1532182 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:00,139 : INFO : EPOCH 4 - PROGRESS: at 72.06% examples, 1533831 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:01,140 : INFO : EPOCH 4 - PROGRESS: at 79.28% examples, 1534089 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:02,144 : INFO : EPOCH 4 - PROGRESS: at 86.39% examples, 1534241 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:35:03,153 : INFO : EPOCH 4 - PROGRESS: at 93.77% examples, 1534736 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:04,008 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:35:04,011 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:35:04,013 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:35:04,017 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:35:04,022 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:35:04,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:35:04,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:35:04,030 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:35:04,030 : INFO : EPOCH - 4 : training on 30031149 raw words (21369651 effective words) took 13.9s, 1534312 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 17:35:05,041 : INFO : EPOCH 5 - PROGRESS: at 7.09% examples, 1504368 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:06,045 : INFO : EPOCH 5 - PROGRESS: at 14.36% examples, 1517225 words/s, in_qsize 13, out_qsize 2\n",
      "2019-08-06 17:35:07,052 : INFO : EPOCH 5 - PROGRESS: at 21.73% examples, 1537370 words/s, in_qsize 15, out_qsize 1\n",
      "2019-08-06 17:35:08,056 : INFO : EPOCH 5 - PROGRESS: at 28.69% examples, 1529102 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:09,061 : INFO : EPOCH 5 - PROGRESS: at 35.98% examples, 1528013 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:10,071 : INFO : EPOCH 5 - PROGRESS: at 43.26% examples, 1530786 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:35:11,079 : INFO : EPOCH 5 - PROGRESS: at 50.60% examples, 1535618 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:12,083 : INFO : EPOCH 5 - PROGRESS: at 57.90% examples, 1538633 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:13,091 : INFO : EPOCH 5 - PROGRESS: at 65.36% examples, 1543530 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:35:14,092 : INFO : EPOCH 5 - PROGRESS: at 72.71% examples, 1544399 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:15,100 : INFO : EPOCH 5 - PROGRESS: at 80.04% examples, 1546317 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:16,101 : INFO : EPOCH 5 - PROGRESS: at 87.07% examples, 1543289 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:35:17,110 : INFO : EPOCH 5 - PROGRESS: at 94.47% examples, 1543175 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:17,847 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:35:17,848 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:35:17,849 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:35:17,853 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:35:17,857 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:35:17,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:35:17,867 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:35:17,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:35:17,869 : INFO : EPOCH - 5 : training on 30031149 raw words (21369827 effective words) took 13.8s, 1544845 effective words/s\n",
      "2019-08-06 17:35:17,870 : INFO : training on a 150155745 raw words (106843495 effective words) took 69.7s, 1532926 effective words/s\n",
      "2019-08-06 17:35:17,870 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-08-06 17:35:17,871 : INFO : training model with 8 workers on 38014 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-08-06 17:35:18,884 : INFO : EPOCH 1 - PROGRESS: at 7.16% examples, 1515562 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:19,894 : INFO : EPOCH 1 - PROGRESS: at 14.55% examples, 1539050 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:20,900 : INFO : EPOCH 1 - PROGRESS: at 21.77% examples, 1538758 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:21,906 : INFO : EPOCH 1 - PROGRESS: at 28.94% examples, 1537424 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:22,907 : INFO : EPOCH 1 - PROGRESS: at 36.36% examples, 1542912 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:23,909 : INFO : EPOCH 1 - PROGRESS: at 43.60% examples, 1542680 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:24,914 : INFO : EPOCH 1 - PROGRESS: at 50.54% examples, 1534226 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:25,918 : INFO : EPOCH 1 - PROGRESS: at 57.77% examples, 1534589 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:35:26,923 : INFO : EPOCH 1 - PROGRESS: at 65.11% examples, 1538928 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:35:27,924 : INFO : EPOCH 1 - PROGRESS: at 72.42% examples, 1539632 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:35:28,931 : INFO : EPOCH 1 - PROGRESS: at 79.85% examples, 1542770 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:29,939 : INFO : EPOCH 1 - PROGRESS: at 87.09% examples, 1543280 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:30,947 : INFO : EPOCH 1 - PROGRESS: at 94.53% examples, 1544405 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:31,681 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:35:31,683 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:35:31,686 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:35:31,688 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:35:31,691 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:35:31,698 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:35:31,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:35:31,704 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:35:31,704 : INFO : EPOCH - 1 : training on 30031149 raw words (21365800 effective words) took 13.8s, 1545166 effective words/s\n",
      "2019-08-06 17:35:32,714 : INFO : EPOCH 2 - PROGRESS: at 7.06% examples, 1500099 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:33,714 : INFO : EPOCH 2 - PROGRESS: at 14.19% examples, 1504030 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:34,719 : INFO : EPOCH 2 - PROGRESS: at 21.38% examples, 1517643 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:35,724 : INFO : EPOCH 2 - PROGRESS: at 28.62% examples, 1525878 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:35:36,728 : INFO : EPOCH 2 - PROGRESS: at 35.91% examples, 1527435 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:37,739 : INFO : EPOCH 2 - PROGRESS: at 43.26% examples, 1532171 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:35:38,746 : INFO : EPOCH 2 - PROGRESS: at 50.48% examples, 1532780 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:39,756 : INFO : EPOCH 2 - PROGRESS: at 57.85% examples, 1536664 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:40,760 : INFO : EPOCH 2 - PROGRESS: at 65.15% examples, 1539323 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:41,765 : INFO : EPOCH 2 - PROGRESS: at 72.45% examples, 1539446 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:42,770 : INFO : EPOCH 2 - PROGRESS: at 79.77% examples, 1540815 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:43,781 : INFO : EPOCH 2 - PROGRESS: at 87.18% examples, 1544266 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:44,783 : INFO : EPOCH 2 - PROGRESS: at 94.53% examples, 1544270 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:45,515 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:35:45,516 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:35:45,517 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:35:45,522 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:35:45,523 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:35:45,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:35:45,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:35:45,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:35:45,537 : INFO : EPOCH - 2 : training on 30031149 raw words (21369074 effective words) took 13.8s, 1545428 effective words/s\n",
      "2019-08-06 17:35:46,547 : INFO : EPOCH 3 - PROGRESS: at 7.16% examples, 1519477 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:35:47,552 : INFO : EPOCH 3 - PROGRESS: at 14.38% examples, 1520889 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:48,553 : INFO : EPOCH 3 - PROGRESS: at 21.44% examples, 1521641 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:49,555 : INFO : EPOCH 3 - PROGRESS: at 28.62% examples, 1526445 words/s, in_qsize 16, out_qsize 2\n",
      "2019-08-06 17:35:50,558 : INFO : EPOCH 3 - PROGRESS: at 35.98% examples, 1531206 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:51,560 : INFO : EPOCH 3 - PROGRESS: at 43.32% examples, 1537717 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:35:52,560 : INFO : EPOCH 3 - PROGRESS: at 50.54% examples, 1539027 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 17:35:53,563 : INFO : EPOCH 3 - PROGRESS: at 57.77% examples, 1539098 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:54,577 : INFO : EPOCH 3 - PROGRESS: at 65.05% examples, 1539764 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:55,583 : INFO : EPOCH 3 - PROGRESS: at 72.42% examples, 1540925 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:56,590 : INFO : EPOCH 3 - PROGRESS: at 79.87% examples, 1544654 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:57,590 : INFO : EPOCH 3 - PROGRESS: at 87.05% examples, 1544979 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:35:58,600 : INFO : EPOCH 3 - PROGRESS: at 94.47% examples, 1544987 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:35:59,342 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:35:59,345 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:35:59,346 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:35:59,349 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:35:59,353 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:35:59,356 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:35:59,361 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:35:59,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:35:59,362 : INFO : EPOCH - 3 : training on 30031149 raw words (21369250 effective words) took 13.8s, 1546325 effective words/s\n",
      "2019-08-06 17:36:00,368 : INFO : EPOCH 4 - PROGRESS: at 6.96% examples, 1482477 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:36:01,374 : INFO : EPOCH 4 - PROGRESS: at 14.33% examples, 1515899 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:36:02,375 : INFO : EPOCH 4 - PROGRESS: at 21.59% examples, 1532869 words/s, in_qsize 13, out_qsize 2\n",
      "2019-08-06 17:36:03,383 : INFO : EPOCH 4 - PROGRESS: at 28.66% examples, 1528814 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:04,392 : INFO : EPOCH 4 - PROGRESS: at 36.10% examples, 1533930 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:05,395 : INFO : EPOCH 4 - PROGRESS: at 43.29% examples, 1533570 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:06,399 : INFO : EPOCH 4 - PROGRESS: at 50.50% examples, 1534830 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:07,399 : INFO : EPOCH 4 - PROGRESS: at 57.62% examples, 1533140 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:08,402 : INFO : EPOCH 4 - PROGRESS: at 64.83% examples, 1534983 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:36:09,409 : INFO : EPOCH 4 - PROGRESS: at 72.26% examples, 1537159 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:10,411 : INFO : EPOCH 4 - PROGRESS: at 79.49% examples, 1537004 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:11,415 : INFO : EPOCH 4 - PROGRESS: at 86.65% examples, 1538224 words/s, in_qsize 16, out_qsize 2\n",
      "2019-08-06 17:36:12,416 : INFO : EPOCH 4 - PROGRESS: at 94.27% examples, 1542564 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:13,176 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:36:13,178 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:36:13,182 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:36:13,183 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:36:13,187 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:36:13,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:36:13,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:36:13,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:36:13,200 : INFO : EPOCH - 4 : training on 30031149 raw words (21367457 effective words) took 13.8s, 1544749 effective words/s\n",
      "2019-08-06 17:36:14,211 : INFO : EPOCH 5 - PROGRESS: at 7.09% examples, 1504640 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:15,215 : INFO : EPOCH 5 - PROGRESS: at 14.24% examples, 1507050 words/s, in_qsize 13, out_qsize 2\n",
      "2019-08-06 17:36:16,220 : INFO : EPOCH 5 - PROGRESS: at 21.49% examples, 1522122 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:17,221 : INFO : EPOCH 5 - PROGRESS: at 28.62% examples, 1525506 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:18,231 : INFO : EPOCH 5 - PROGRESS: at 35.91% examples, 1525273 words/s, in_qsize 15, out_qsize 1\n",
      "2019-08-06 17:36:19,240 : INFO : EPOCH 5 - PROGRESS: at 43.17% examples, 1529018 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:20,243 : INFO : EPOCH 5 - PROGRESS: at 50.44% examples, 1531798 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:21,248 : INFO : EPOCH 5 - PROGRESS: at 57.87% examples, 1538452 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:22,253 : INFO : EPOCH 5 - PROGRESS: at 65.11% examples, 1539116 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:36:23,255 : INFO : EPOCH 5 - PROGRESS: at 72.42% examples, 1539547 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:24,256 : INFO : EPOCH 5 - PROGRESS: at 79.72% examples, 1541013 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:25,260 : INFO : EPOCH 5 - PROGRESS: at 86.80% examples, 1539934 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:26,279 : INFO : EPOCH 5 - PROGRESS: at 94.12% examples, 1537540 words/s, in_qsize 15, out_qsize 3\n",
      "2019-08-06 17:36:27,044 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:36:27,046 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:36:27,050 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:36:27,051 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:36:27,052 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:36:27,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:36:27,063 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:36:27,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:36:27,065 : INFO : EPOCH - 5 : training on 30031149 raw words (21370764 effective words) took 13.9s, 1541875 effective words/s\n",
      "2019-08-06 17:36:28,077 : INFO : EPOCH 6 - PROGRESS: at 7.09% examples, 1506604 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:29,078 : INFO : EPOCH 6 - PROGRESS: at 14.36% examples, 1521539 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:30,080 : INFO : EPOCH 6 - PROGRESS: at 21.57% examples, 1530489 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:31,087 : INFO : EPOCH 6 - PROGRESS: at 28.67% examples, 1528188 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:36:32,090 : INFO : EPOCH 6 - PROGRESS: at 35.91% examples, 1528315 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:33,093 : INFO : EPOCH 6 - PROGRESS: at 43.19% examples, 1532703 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:34,095 : INFO : EPOCH 6 - PROGRESS: at 50.41% examples, 1534130 words/s, in_qsize 13, out_qsize 2\n",
      "2019-08-06 17:36:35,103 : INFO : EPOCH 6 - PROGRESS: at 57.57% examples, 1533033 words/s, in_qsize 13, out_qsize 2\n",
      "2019-08-06 17:36:36,108 : INFO : EPOCH 6 - PROGRESS: at 64.78% examples, 1534515 words/s, in_qsize 15, out_qsize 1\n",
      "2019-08-06 17:36:37,115 : INFO : EPOCH 6 - PROGRESS: at 72.12% examples, 1534551 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:38,118 : INFO : EPOCH 6 - PROGRESS: at 79.30% examples, 1533980 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:39,118 : INFO : EPOCH 6 - PROGRESS: at 86.53% examples, 1536517 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:40,119 : INFO : EPOCH 6 - PROGRESS: at 93.90% examples, 1537627 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:40,938 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:36:40,944 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:36:40,945 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:36:40,946 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:36:40,949 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 17:36:40,953 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:36:40,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:36:40,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:36:40,960 : INFO : EPOCH - 6 : training on 30031149 raw words (21371192 effective words) took 13.9s, 1539034 effective words/s\n",
      "2019-08-06 17:36:41,973 : INFO : EPOCH 7 - PROGRESS: at 7.03% examples, 1488824 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:42,977 : INFO : EPOCH 7 - PROGRESS: at 14.28% examples, 1509675 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:43,980 : INFO : EPOCH 7 - PROGRESS: at 21.38% examples, 1515759 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:44,983 : INFO : EPOCH 7 - PROGRESS: at 28.71% examples, 1530491 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:45,984 : INFO : EPOCH 7 - PROGRESS: at 35.98% examples, 1530817 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:36:46,988 : INFO : EPOCH 7 - PROGRESS: at 43.15% examples, 1530859 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:47,992 : INFO : EPOCH 7 - PROGRESS: at 50.48% examples, 1535279 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:36:48,994 : INFO : EPOCH 7 - PROGRESS: at 57.72% examples, 1536801 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:50,001 : INFO : EPOCH 7 - PROGRESS: at 64.88% examples, 1535774 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:51,007 : INFO : EPOCH 7 - PROGRESS: at 72.23% examples, 1536708 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:52,007 : INFO : EPOCH 7 - PROGRESS: at 79.44% examples, 1537076 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:53,015 : INFO : EPOCH 7 - PROGRESS: at 86.53% examples, 1535905 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:54,017 : INFO : EPOCH 7 - PROGRESS: at 93.74% examples, 1534140 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:54,856 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:36:54,857 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:36:54,858 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:36:54,862 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:36:54,866 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:36:54,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:36:54,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:36:54,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:36:54,875 : INFO : EPOCH - 7 : training on 30031149 raw words (21370570 effective words) took 13.9s, 1536447 effective words/s\n",
      "2019-08-06 17:36:55,889 : INFO : EPOCH 8 - PROGRESS: at 7.12% examples, 1507733 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:56,891 : INFO : EPOCH 8 - PROGRESS: at 14.41% examples, 1524079 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:36:57,901 : INFO : EPOCH 8 - PROGRESS: at 21.56% examples, 1523704 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:36:58,902 : INFO : EPOCH 8 - PROGRESS: at 28.73% examples, 1530530 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:36:59,905 : INFO : EPOCH 8 - PROGRESS: at 35.95% examples, 1527152 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:00,911 : INFO : EPOCH 8 - PROGRESS: at 43.15% examples, 1528848 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:01,914 : INFO : EPOCH 8 - PROGRESS: at 50.38% examples, 1530607 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:37:02,914 : INFO : EPOCH 8 - PROGRESS: at 57.48% examples, 1530608 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:03,919 : INFO : EPOCH 8 - PROGRESS: at 64.66% examples, 1531649 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:04,926 : INFO : EPOCH 8 - PROGRESS: at 72.00% examples, 1530949 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:05,934 : INFO : EPOCH 8 - PROGRESS: at 79.31% examples, 1532592 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:37:06,938 : INFO : EPOCH 8 - PROGRESS: at 86.52% examples, 1534629 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:07,952 : INFO : EPOCH 8 - PROGRESS: at 93.95% examples, 1535111 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:08,764 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:37:08,766 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:37:08,767 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:37:08,774 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:37:08,775 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:37:08,779 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:37:08,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:37:08,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:37:08,787 : INFO : EPOCH - 8 : training on 30031149 raw words (21370360 effective words) took 13.9s, 1536748 effective words/s\n",
      "2019-08-06 17:37:09,794 : INFO : EPOCH 9 - PROGRESS: at 7.16% examples, 1526108 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:10,795 : INFO : EPOCH 9 - PROGRESS: at 14.46% examples, 1537481 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:11,804 : INFO : EPOCH 9 - PROGRESS: at 21.77% examples, 1545445 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:12,812 : INFO : EPOCH 9 - PROGRESS: at 28.96% examples, 1543885 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:37:13,813 : INFO : EPOCH 9 - PROGRESS: at 36.20% examples, 1540030 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:14,817 : INFO : EPOCH 9 - PROGRESS: at 43.30% examples, 1535189 words/s, in_qsize 16, out_qsize 1\n",
      "2019-08-06 17:37:15,820 : INFO : EPOCH 9 - PROGRESS: at 50.60% examples, 1539427 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:16,822 : INFO : EPOCH 9 - PROGRESS: at 57.62% examples, 1534174 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:17,828 : INFO : EPOCH 9 - PROGRESS: at 64.98% examples, 1538337 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:18,833 : INFO : EPOCH 9 - PROGRESS: at 72.12% examples, 1534916 words/s, in_qsize 15, out_qsize 1\n",
      "2019-08-06 17:37:19,834 : INFO : EPOCH 9 - PROGRESS: at 79.30% examples, 1534584 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:20,840 : INFO : EPOCH 9 - PROGRESS: at 86.34% examples, 1533203 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:21,847 : INFO : EPOCH 9 - PROGRESS: at 93.74% examples, 1533852 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:22,697 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:37:22,701 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:37:22,702 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:37:22,708 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:37:22,709 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:37:22,714 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:37:22,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:37:22,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:37:22,720 : INFO : EPOCH - 9 : training on 30031149 raw words (21370689 effective words) took 13.9s, 1534458 effective words/s\n",
      "2019-08-06 17:37:23,738 : INFO : EPOCH 10 - PROGRESS: at 7.06% examples, 1495676 words/s, in_qsize 13, out_qsize 2\n",
      "2019-08-06 17:37:24,739 : INFO : EPOCH 10 - PROGRESS: at 14.46% examples, 1533385 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:37:25,744 : INFO : EPOCH 10 - PROGRESS: at 21.75% examples, 1542370 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:37:26,745 : INFO : EPOCH 10 - PROGRESS: at 28.90% examples, 1542390 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:37:27,756 : INFO : EPOCH 10 - PROGRESS: at 36.24% examples, 1540002 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:28,767 : INFO : EPOCH 10 - PROGRESS: at 43.48% examples, 1539216 words/s, in_qsize 16, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 17:37:29,778 : INFO : EPOCH 10 - PROGRESS: at 50.69% examples, 1538175 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:30,779 : INFO : EPOCH 10 - PROGRESS: at 57.87% examples, 1537620 words/s, in_qsize 15, out_qsize 1\n",
      "2019-08-06 17:37:31,779 : INFO : EPOCH 10 - PROGRESS: at 65.05% examples, 1537546 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:37:32,784 : INFO : EPOCH 10 - PROGRESS: at 72.40% examples, 1538653 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:33,786 : INFO : EPOCH 10 - PROGRESS: at 79.75% examples, 1541036 words/s, in_qsize 14, out_qsize 1\n",
      "2019-08-06 17:37:34,796 : INFO : EPOCH 10 - PROGRESS: at 86.89% examples, 1540544 words/s, in_qsize 15, out_qsize 0\n",
      "2019-08-06 17:37:35,802 : INFO : EPOCH 10 - PROGRESS: at 94.23% examples, 1539716 words/s, in_qsize 16, out_qsize 0\n",
      "2019-08-06 17:37:36,572 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-08-06 17:37:36,573 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-08-06 17:37:36,574 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-08-06 17:37:36,581 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-08-06 17:37:36,582 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-06 17:37:36,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-06 17:37:36,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-06 17:37:36,595 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-06 17:37:36,595 : INFO : EPOCH - 10 : training on 30031149 raw words (21369232 effective words) took 13.9s, 1541445 effective words/s\n",
      "2019-08-06 17:37:36,596 : INFO : training on a 300311490 raw words (213694388 effective words) took 138.7s, 1540427 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(213694388, 300311490)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(documents, size=150, window=10, min_count=2, workers=8)\n",
    "model.train(documents, total_examples=len(documents), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Word Vectors\n",
    "***\n",
    "Now we can do fun things with our learned word vectors!\n",
    "## Look up Words Similar to \"dirty\"\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 17:43:16,863 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8175210952758789),\n",
       " ('stained', 0.8072519898414612),\n",
       " ('unclean', 0.7810685634613037),\n",
       " ('dusty', 0.7645260095596313),\n",
       " ('scratched', 0.6971113681793213),\n",
       " ('smelly', 0.692798912525177),\n",
       " ('damaged', 0.6831164956092834),\n",
       " ('torn', 0.6799750924110413),\n",
       " ('sticky', 0.672492265701294),\n",
       " ('threadbare', 0.6706531643867493)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = \"dirty\"\n",
    "model.wv.most_similar( positive=target_word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.8741446733474731),\n",
       " ('cheerful', 0.7976503968238831),\n",
       " ('welcoming', 0.7975963950157166),\n",
       " ('attentive', 0.7734375596046448),\n",
       " ('professional', 0.7597354650497437),\n",
       " ('freindly', 0.7273843288421631),\n",
       " ('kind', 0.726075291633606),\n",
       " ('pleasant', 0.6902655363082886),\n",
       " ('friendly', 0.682566225528717),\n",
       " ('accommodating', 0.6726747751235962)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = \"polite\"\n",
    "model.wv.most_similar( positive=target_word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('italy', 0.5549201369285583),\n",
       " ('netherlands', 0.5487757921218872),\n",
       " ('austria', 0.4729192554950714),\n",
       " ('spain', 0.4533565044403076),\n",
       " ('iraq', 0.39420443773269653),\n",
       " ('morocco', 0.38039430975914),\n",
       " ('algeria', 0.37401291728019714),\n",
       " ('lisle', 0.37372440099716187),\n",
       " ('slovenia', 0.3700857162475586),\n",
       " ('th', 0.35027825832366943)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = \"france\"\n",
    "model.wv.most_similar( positive=target_word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('surprised', 0.7705385088920593),\n",
       " ('appalled', 0.705019474029541),\n",
       " ('annoyed', 0.6508231163024902),\n",
       " ('upset', 0.6485998034477234),\n",
       " ('disgusted', 0.6214147210121155),\n",
       " ('suprised', 0.6194778680801392),\n",
       " ('amazed', 0.6169865131378174),\n",
       " ('disappointed', 0.5991095900535583),\n",
       " ('dissapointed', 0.588792085647583),\n",
       " ('excited', 0.5861113667488098)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = \"shocked\"\n",
    "model.wv.most_similar( positive=target_word )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also provide negative examples so you can add more selective filtering on similar words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.7301138043403625),\n",
       " ('comforter', 0.7002500891685486),\n",
       " ('mattress', 0.6890642046928406),\n",
       " ('blanket', 0.6781498789787292),\n",
       " ('quilt', 0.6764400601387024),\n",
       " ('pillows', 0.6585404276847839),\n",
       " ('bedding', 0.6240412592887878),\n",
       " ('matress', 0.6225305199623108),\n",
       " ('duvets', 0.6080532073974609),\n",
       " ('protector', 0.5990015864372253)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "positive_examples = [\"bed\",'sheet','pillow']\n",
    "negative_examples = ['couch']\n",
    "model.wv.most_similar(positive=positive_examples,negative=negative_examples,topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity between two words in the vocabulary\n",
    "***\n",
    "The following snippets compute the cosine similarity between the specified word vectors of the input words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927988990782136"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity( w1=\"dirty\", w2=\"smelly\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2088930286059534"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Odd One Out\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/miniconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py:730: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications\n",
    "***\n",
    "You can use Word2Vec to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you develop this lexicon.\n",
    "\n",
    "If you had tags for a million stackoverflow questions and answers, one could find tags related to a given tag and recommend related ones for exploration. You do this by treating each set of co-occurring tags as a sentence and train a Word2Vec model on this data"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
