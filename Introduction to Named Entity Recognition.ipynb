{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy is known for industrial-grade NLP in python. It is written in Cython. We are going to be working on Named Entity Recognition tagging here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = '''\n",
    "Asian shares skidded on Tuesday after a rout in tech stocks put Wall Street to the sword, while a \n",
    "sharp drop in oil prices and political risks in Europe pushed the dollar to 16-month highs as investors dumped \n",
    "riskier assets. MSCI’s broadest index of Asia-Pacific shares outside Japan dropped 1.7 percent to a 1-1/2 \n",
    "week trough, with Australian shares sinking 1.6 percent. Japan’s Nikkei dived 3.1 percent led by losses in \n",
    "electric machinery makers and suppliers of Apple’s iphone parts. Sterling fell to $1.286 after three straight \n",
    "sessions of losses took it to the lowest since Nov.1 as there were still considerable unresolved issues with the\n",
    "European Union over Brexit, British Prime Minister Theresa May said on Monday.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: GPE, Value: \n",
      "\n",
      "Type: NORP, Value: Asian\n",
      "Type: DATE, Value: Tuesday\n",
      "Type: GPE, Value: \n",
      "\n",
      "Type: LOC, Value: Europe\n",
      "Type: CARDINAL, Value: 16-month\n",
      "Type: GPE, Value: \n",
      "\n",
      "Type: ORG, Value: MSCI\n",
      "Type: LOC, Value: Asia-Pacific\n",
      "Type: GPE, Value: Japan\n",
      "Type: PERCENT, Value: 1.7 percent\n",
      "Type: DATE, Value: a 1-1/2 \n",
      "week\n",
      "Type: NORP, Value: Australian\n",
      "Type: PERCENT, Value: 1.6 percent\n",
      "Type: GPE, Value: Japan\n",
      "Type: PERCENT, Value: 3.1 percent\n",
      "Type: GPE, Value: \n",
      "\n",
      "Type: ORG, Value: Apple\n",
      "Type: MONEY, Value: 1.286\n",
      "Type: CARDINAL, Value: three\n",
      "Type: GPE, Value: \n",
      "\n",
      "Type: ORG, Value: the\n",
      "European Union\n",
      "Type: GPE, Value: Brexit\n",
      "Type: NORP, Value: British\n",
      "Type: PERSON, Value: Theresa May\n",
      "Type: DATE, Value: Monday\n"
     ]
    }
   ],
   "source": [
    "document = spacy_nlp(article)\n",
    "for entity in document.ents:\n",
    "    print(\"Type: {}, Value: {}\".format(entity.label_,entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supported entity types are:\n",
    "Person - people, including fictional\n",
    "NORP - natinoalities or religious or political groups\n",
    "FAC - buildings, airports, highways, bridges, etc.\n",
    "ORG - companies, agencies, institutions\n",
    "GPE - countries, cities, states\n",
    "LOC - non-gpe locations, mountain ranges, bodies of water\n",
    "PRODUCT - objects, vehicles, foods, etc. (not services)\n",
    "EVENT - named hurricanes, battles, wars, sports events\n",
    "WORK_OF_ART - titles of books, songs, etc.\n",
    "LAW - named documents made into laws\n",
    "LANGUAGE - any named language\n",
    "DATE - absolute or relative dates or periods\n",
    "TIME - time smaller than a day\n",
    "PERCENT - percentage, including \"%\"\n",
    "MONEY - monetary values, including unit\n",
    "QUANTITY - measurements, weight or distance\n",
    "ORDINAL - \"first\", \"second\"\n",
    "CARDINAL - numerals that do not fall under another type\n",
    "\n",
    "NLTK (Natural Language Toolkit) is a python package that provides a set of natural languages corpora and APIs of wide varieties of NLP algorithms. TO perform Named Entity Recognition using NLTK, it is done in three stages:\n",
    "1. Word Tokenization\n",
    "2. Parts of Speech (POS) tagging\n",
    "3. Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/joseph/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/joseph/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/joseph/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/joseph/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, we needed to download some standard corpora and API from NLTK to perform parts of speech tagging and named entity recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Asian', 'JJ'),\n",
       " ('shares', 'NNS'),\n",
       " ('skidded', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('Tuesday', 'NNP'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('rout', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('tech', 'JJ'),\n",
       " ('stocks', 'NNS'),\n",
       " ('put', 'VBD'),\n",
       " ('Wall', 'NNP'),\n",
       " ('Street', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('sword', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('sharp', 'JJ'),\n",
       " ('drop', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('oil', 'NN'),\n",
       " ('prices', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('political', 'JJ'),\n",
       " ('risks', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('Europe', 'NNP'),\n",
       " ('pushed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('dollar', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('16-month', 'JJ'),\n",
       " ('highs', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('investors', 'NNS'),\n",
       " ('dumped', 'VBD'),\n",
       " ('riskier', 'JJR'),\n",
       " ('assets', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('MSCI', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('broadest', 'JJS'),\n",
       " ('index', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Asia-Pacific', 'NNP'),\n",
       " ('shares', 'NNS'),\n",
       " ('outside', 'IN'),\n",
       " ('Japan', 'NNP'),\n",
       " ('dropped', 'VBD'),\n",
       " ('1.7', 'CD'),\n",
       " ('percent', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('a', 'DT'),\n",
       " ('1-1/2', 'JJ'),\n",
       " ('week', 'NN'),\n",
       " ('trough', 'NN'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('Australian', 'JJ'),\n",
       " ('shares', 'NNS'),\n",
       " ('sinking', 'VBG'),\n",
       " ('1.6', 'CD'),\n",
       " ('percent', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Japan', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('Nikkei', 'NNP'),\n",
       " ('dived', 'VBD'),\n",
       " ('3.1', 'CD'),\n",
       " ('percent', 'NN'),\n",
       " ('led', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('losses', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('electric', 'JJ'),\n",
       " ('machinery', 'NN'),\n",
       " ('makers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('suppliers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Apple', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('iphone', 'NN'),\n",
       " ('parts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Sterling', 'NN'),\n",
       " ('fell', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('$', '$'),\n",
       " ('1.286', 'CD'),\n",
       " ('after', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('straight', 'JJ'),\n",
       " ('sessions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('losses', 'NNS'),\n",
       " ('took', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('lowest', 'JJS'),\n",
       " ('since', 'IN'),\n",
       " ('Nov.1', 'NNP'),\n",
       " ('as', 'IN'),\n",
       " ('there', 'EX'),\n",
       " ('were', 'VBD'),\n",
       " ('still', 'RB'),\n",
       " ('considerable', 'JJ'),\n",
       " ('unresolved', 'JJ'),\n",
       " ('issues', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('European', 'NNP'),\n",
       " ('Union', 'NNP'),\n",
       " ('over', 'IN'),\n",
       " ('Brexit', 'NNP'),\n",
       " (',', ','),\n",
       " ('British', 'NNP'),\n",
       " ('Prime', 'NNP'),\n",
       " ('Minister', 'NNP'),\n",
       " ('Theresa', 'NNP'),\n",
       " ('May', 'NNP'),\n",
       " ('said', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('Monday', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess( sentence ):\n",
    "    sentence = nltk.word_tokenize(sentence)\n",
    "    sentence = nltk.pos_tag(sentence)\n",
    "    return sentence\n",
    "\n",
    "sentence_processed = preprocess( article )\n",
    "sentence_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes are labeled as follows:\n",
    "\n",
    "CC - coordinating conjunction\n",
    "\n",
    "CD - cardinal digit\n",
    "\n",
    "DT - determiner\n",
    "\n",
    "EX - existential here (\"there exists\" instead of \"there is\")\n",
    "\n",
    "FW - foreign word\n",
    "\n",
    "IN - preposition/subordinating conjunction\n",
    "\n",
    "JJ - adjective 'big'\n",
    "\n",
    "JJR - adjective comparative 'bigger'\n",
    "\n",
    "JJS - adjective superlative 'biggest'\n",
    "\n",
    "LS - list marker\n",
    "\n",
    "MD - modal could, will\n",
    "\n",
    "NN - noun, singular 'desk'\n",
    "\n",
    "NNS - noun plural 'desks'\n",
    "\n",
    "NNP - proper noun, singular 'Harrison'\n",
    "\n",
    "NNPS - proper noun, plural \"Americans\"\n",
    "\n",
    "PDT - predeterminer 'all the kids'\n",
    "\n",
    "POS - possessive ending parent's\n",
    "\n",
    "PRP - presonal pronoun I, he, she\n",
    "\n",
    "PRP$ - possess pronoun my, his, hers\n",
    "\n",
    "RB - adverb very, silently\n",
    "\n",
    "RBR - adverb, comparative better\n",
    "\n",
    "RBS - adverb, superlative best\n",
    "\n",
    "RP - particle give up\n",
    "\n",
    "TO - to go 'to' the store\n",
    "\n",
    "VB - verb, base form take\n",
    "\n",
    "VDB - verb, past tense took\n",
    "\n",
    "VBG - verb, gerund/present participle taking\n",
    "\n",
    "VBP - verb, sing. present, non-3d take\n",
    "\n",
    "VBZ - verb, 3d person sing. present takes\n",
    "\n",
    "WDT - wh-determiner which\n",
    "\n",
    "WP - wh-pronoun, who, what\n",
    "\n",
    "WP$ - possessive wh-pronoun, whose\n",
    "\n",
    "WRB - wh-adverb where, when\n",
    "\n",
    "After we do the parts-of-speech tagging, we need to do **chunking**. This follows POS tagging to add more structure to the sentence. The result is grouping of words in \"chunks\"\n",
    "\n",
    "Here, we only want to NER tag the Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shares/NNS\n",
      "  Tuesday/NNP\n",
      "  rout/NN\n",
      "  stocks/NNS\n",
      "  (FACILITY Wall/NNP Street/NNP)\n",
      "  sword/NN\n",
      "  drop/NN\n",
      "  oil/NN\n",
      "  prices/NNS\n",
      "  risks/NNS\n",
      "  (GPE Europe/NNP)\n",
      "  dollar/NN\n",
      "  highs/NNS\n",
      "  investors/NNS\n",
      "  assets/NNS\n",
      "  (ORGANIZATION MSCI/NNP)\n",
      "  ’/NNP\n",
      "  index/NN\n",
      "  Asia-Pacific/NNP\n",
      "  shares/NNS\n",
      "  (GPE Japan/NNP)\n",
      "  percent/NN\n",
      "  week/NN\n",
      "  trough/NN\n",
      "  shares/NNS\n",
      "  percent/NN\n",
      "  (PERSON Japan/NNP)\n",
      "  ’/NNP\n",
      "  (PERSON Nikkei/NNP)\n",
      "  percent/NN\n",
      "  losses/NNS\n",
      "  machinery/NN\n",
      "  makers/NNS\n",
      "  suppliers/NNS\n",
      "  (PERSON Apple/NNP)\n",
      "  ’/NNP\n",
      "  iphone/NN\n",
      "  parts/NNS\n",
      "  (PERSON Sterling/NN)\n",
      "  sessions/NNS\n",
      "  losses/NNS\n",
      "  Nov.1/NNP\n",
      "  issues/NNS\n",
      "  (ORGANIZATION European/NNP Union/NNP)\n",
      "  (GPE Brexit/NNP)\n",
      "  (GPE British/NNP)\n",
      "  Prime/NNP\n",
      "  Minister/NNP\n",
      "  (PERSON Theresa/NNP May/NNP)\n",
      "  Monday/NNP\n"
     ]
    }
   ],
   "source": [
    "chunks = ne_chunk( sentence_processed )\n",
    "\n",
    "for x in str(chunks).split('\\n'):\n",
    "    if '/NN' in x:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks okay, but not great. We can manually implement a pattern for performing the chunking. We can say that a noun phrase, (NP) is formed whenever the chunker finds an optional determiner (DT), followed by any number of adjectives (JJ) and then a noun (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Asian/JJ\n",
      "  shares/NNS\n",
      "  skidded/VBN\n",
      "  on/IN\n",
      "  Tuesday/NNP\n",
      "  after/IN\n",
      "  (NP a/DT rout/NN)\n",
      "  in/IN\n",
      "  tech/JJ\n",
      "  stocks/NNS\n",
      "  put/VBD\n",
      "  Wall/NNP\n",
      "  Street/NNP\n",
      "  to/TO\n",
      "  (NP the/DT sword/NN)\n",
      "  ,/,\n",
      "  while/IN\n",
      "  (NP a/DT sharp/JJ drop/NN)\n",
      "  in/IN\n",
      "  (NP oil/NN)\n",
      "  prices/NNS\n",
      "  and/CC\n",
      "  political/JJ\n",
      "  risks/NNS\n",
      "  in/IN\n",
      "  Europe/NNP\n",
      "  pushed/VBD\n",
      "  (NP the/DT dollar/NN)\n",
      "  to/TO\n",
      "  16-month/JJ\n",
      "  highs/NNS\n",
      "  as/IN\n",
      "  investors/NNS\n",
      "  dumped/VBD\n",
      "  riskier/JJR\n",
      "  assets/NNS\n",
      "  ./.\n",
      "  MSCI/NNP\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  broadest/JJS\n",
      "  (NP index/NN)\n",
      "  of/IN\n",
      "  Asia-Pacific/NNP\n",
      "  shares/NNS\n",
      "  outside/IN\n",
      "  Japan/NNP\n",
      "  dropped/VBD\n",
      "  1.7/CD\n",
      "  (NP percent/NN)\n",
      "  to/TO\n",
      "  (NP a/DT 1-1/2/JJ week/NN)\n",
      "  (NP trough/NN)\n",
      "  ,/,\n",
      "  with/IN\n",
      "  Australian/JJ\n",
      "  shares/NNS\n",
      "  sinking/VBG\n",
      "  1.6/CD\n",
      "  (NP percent/NN)\n",
      "  ./.\n",
      "  Japan/NNP\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  Nikkei/NNP\n",
      "  dived/VBD\n",
      "  3.1/CD\n",
      "  (NP percent/NN)\n",
      "  led/VBN\n",
      "  by/IN\n",
      "  losses/NNS\n",
      "  in/IN\n",
      "  (NP electric/JJ machinery/NN)\n",
      "  makers/NNS\n",
      "  and/CC\n",
      "  suppliers/NNS\n",
      "  of/IN\n",
      "  Apple/NNP\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  (NP iphone/NN)\n",
      "  parts/NNS\n",
      "  ./.\n",
      "  (NP Sterling/NN)\n",
      "  fell/VBD\n",
      "  to/TO\n",
      "  $/$\n",
      "  1.286/CD\n",
      "  after/IN\n",
      "  three/CD\n",
      "  straight/JJ\n",
      "  sessions/NNS\n",
      "  of/IN\n",
      "  losses/NNS\n",
      "  took/VBD\n",
      "  it/PRP\n",
      "  to/TO\n",
      "  the/DT\n",
      "  lowest/JJS\n",
      "  since/IN\n",
      "  Nov.1/NNP\n",
      "  as/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  still/RB\n",
      "  considerable/JJ\n",
      "  unresolved/JJ\n",
      "  issues/NNS\n",
      "  with/IN\n",
      "  the/DT\n",
      "  European/NNP\n",
      "  Union/NNP\n",
      "  over/IN\n",
      "  Brexit/NNP\n",
      "  ,/,\n",
      "  British/NNP\n",
      "  Prime/NNP\n",
      "  Minister/NNP\n",
      "  Theresa/NNP\n",
      "  May/NNP\n",
      "  said/VBD\n",
      "  on/IN\n",
      "  Monday/NNP\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse( sentence_processed)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output has a tree structure, and \"S\" means the sentence is the first level. A more aceptable format is called IOB tags (Inside, Outside, Beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Asian', 'JJ', 'O'),\n",
      " ('shares', 'NNS', 'O'),\n",
      " ('skidded', 'VBN', 'O'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('Tuesday', 'NNP', 'O'),\n",
      " ('after', 'IN', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('rout', 'NN', 'I-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('tech', 'JJ', 'O'),\n",
      " ('stocks', 'NNS', 'O'),\n",
      " ('put', 'VBD', 'O'),\n",
      " ('Wall', 'NNP', 'O'),\n",
      " ('Street', 'NNP', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('sword', 'NN', 'I-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('while', 'IN', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('sharp', 'JJ', 'I-NP'),\n",
      " ('drop', 'NN', 'I-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('oil', 'NN', 'B-NP'),\n",
      " ('prices', 'NNS', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('political', 'JJ', 'O'),\n",
      " ('risks', 'NNS', 'O'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('Europe', 'NNP', 'O'),\n",
      " ('pushed', 'VBD', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('dollar', 'NN', 'I-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('16-month', 'JJ', 'O'),\n",
      " ('highs', 'NNS', 'O'),\n",
      " ('as', 'IN', 'O'),\n",
      " ('investors', 'NNS', 'O'),\n",
      " ('dumped', 'VBD', 'O'),\n",
      " ('riskier', 'JJR', 'O'),\n",
      " ('assets', 'NNS', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('MSCI', 'NNP', 'O'),\n",
      " ('’', 'NNP', 'O'),\n",
      " ('s', 'VBD', 'O'),\n",
      " ('broadest', 'JJS', 'O'),\n",
      " ('index', 'NN', 'B-NP'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('Asia-Pacific', 'NNP', 'O'),\n",
      " ('shares', 'NNS', 'O'),\n",
      " ('outside', 'IN', 'O'),\n",
      " ('Japan', 'NNP', 'O'),\n",
      " ('dropped', 'VBD', 'O'),\n",
      " ('1.7', 'CD', 'O'),\n",
      " ('percent', 'NN', 'B-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('1-1/2', 'JJ', 'I-NP'),\n",
      " ('week', 'NN', 'I-NP'),\n",
      " ('trough', 'NN', 'B-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('with', 'IN', 'O'),\n",
      " ('Australian', 'JJ', 'O'),\n",
      " ('shares', 'NNS', 'O'),\n",
      " ('sinking', 'VBG', 'O'),\n",
      " ('1.6', 'CD', 'O'),\n",
      " ('percent', 'NN', 'B-NP'),\n",
      " ('.', '.', 'O'),\n",
      " ('Japan', 'NNP', 'O'),\n",
      " ('’', 'NNP', 'O'),\n",
      " ('s', 'VBD', 'O'),\n",
      " ('Nikkei', 'NNP', 'O'),\n",
      " ('dived', 'VBD', 'O'),\n",
      " ('3.1', 'CD', 'O'),\n",
      " ('percent', 'NN', 'B-NP'),\n",
      " ('led', 'VBN', 'O'),\n",
      " ('by', 'IN', 'O'),\n",
      " ('losses', 'NNS', 'O'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('electric', 'JJ', 'B-NP'),\n",
      " ('machinery', 'NN', 'I-NP'),\n",
      " ('makers', 'NNS', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('suppliers', 'NNS', 'O'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('Apple', 'NNP', 'O'),\n",
      " ('’', 'NNP', 'O'),\n",
      " ('s', 'VBD', 'O'),\n",
      " ('iphone', 'NN', 'B-NP'),\n",
      " ('parts', 'NNS', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('Sterling', 'NN', 'B-NP'),\n",
      " ('fell', 'VBD', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('$', '$', 'O'),\n",
      " ('1.286', 'CD', 'O'),\n",
      " ('after', 'IN', 'O'),\n",
      " ('three', 'CD', 'O'),\n",
      " ('straight', 'JJ', 'O'),\n",
      " ('sessions', 'NNS', 'O'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('losses', 'NNS', 'O'),\n",
      " ('took', 'VBD', 'O'),\n",
      " ('it', 'PRP', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('the', 'DT', 'O'),\n",
      " ('lowest', 'JJS', 'O'),\n",
      " ('since', 'IN', 'O'),\n",
      " ('Nov.1', 'NNP', 'O'),\n",
      " ('as', 'IN', 'O'),\n",
      " ('there', 'EX', 'O'),\n",
      " ('were', 'VBD', 'O'),\n",
      " ('still', 'RB', 'O'),\n",
      " ('considerable', 'JJ', 'O'),\n",
      " ('unresolved', 'JJ', 'O'),\n",
      " ('issues', 'NNS', 'O'),\n",
      " ('with', 'IN', 'O'),\n",
      " ('the', 'DT', 'O'),\n",
      " ('European', 'NNP', 'O'),\n",
      " ('Union', 'NNP', 'O'),\n",
      " ('over', 'IN', 'O'),\n",
      " ('Brexit', 'NNP', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('British', 'NNP', 'O'),\n",
      " ('Prime', 'NNP', 'O'),\n",
      " ('Minister', 'NNP', 'O'),\n",
      " ('Theresa', 'NNP', 'O'),\n",
      " ('May', 'NNP', 'O'),\n",
      " ('said', 'VBD', 'O'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('Monday', 'NNP', 'O'),\n",
      " ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the output is a line with a parts of speech and named entity tagged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian JJ O\n",
      "shares NNS O\n",
      "skidded VBN O\n",
      "on IN O\n",
      "Tuesday NNP O\n",
      "after IN O\n",
      "a DT B-NP\n",
      "rout NN I-NP\n",
      "in IN O\n",
      "tech JJ O\n",
      "stocks NNS O\n",
      "put VBD O\n",
      "Wall NNP O\n",
      "Street NNP O\n",
      "to TO O\n",
      "the DT B-NP\n",
      "sword NN I-NP\n",
      ", , O\n",
      "while IN O\n",
      "a DT B-NP\n",
      "sharp JJ I-NP\n",
      "drop NN I-NP\n",
      "in IN O\n",
      "oil NN B-NP\n",
      "prices NNS O\n",
      "and CC O\n",
      "political JJ O\n",
      "risks NNS O\n",
      "in IN O\n",
      "Europe NNP O\n",
      "pushed VBD O\n",
      "the DT B-NP\n",
      "dollar NN I-NP\n",
      "to TO O\n",
      "16-month JJ O\n",
      "highs NNS O\n",
      "as IN O\n",
      "investors NNS O\n",
      "dumped VBD O\n",
      "riskier JJR O\n",
      "assets NNS O\n",
      ". . O\n",
      "MSCI NNP O\n",
      "’ NNP O\n",
      "s VBD O\n",
      "broadest JJS O\n",
      "index NN B-NP\n",
      "of IN O\n",
      "Asia-Pacific NNP O\n",
      "shares NNS O\n",
      "outside IN O\n",
      "Japan NNP O\n",
      "dropped VBD O\n",
      "1.7 CD O\n",
      "percent NN B-NP\n",
      "to TO O\n",
      "a DT B-NP\n",
      "1-1/2 JJ I-NP\n",
      "week NN I-NP\n",
      "trough NN B-NP\n",
      ", , O\n",
      "with IN O\n",
      "Australian JJ O\n",
      "shares NNS O\n",
      "sinking VBG O\n",
      "1.6 CD O\n",
      "percent NN B-NP\n",
      ". . O\n",
      "Japan NNP O\n",
      "’ NNP O\n",
      "s VBD O\n",
      "Nikkei NNP O\n",
      "dived VBD O\n",
      "3.1 CD O\n",
      "percent NN B-NP\n",
      "led VBN O\n",
      "by IN O\n",
      "losses NNS O\n",
      "in IN O\n",
      "electric JJ B-NP\n",
      "machinery NN I-NP\n",
      "makers NNS O\n",
      "and CC O\n",
      "suppliers NNS O\n",
      "of IN O\n",
      "Apple NNP O\n",
      "’ NNP O\n",
      "s VBD O\n",
      "iphone NN B-NP\n",
      "parts NNS O\n",
      ". . O\n",
      "Sterling NN B-NP\n",
      "fell VBD O\n",
      "to TO O\n",
      "$ $ O\n",
      "1.286 CD O\n",
      "after IN O\n",
      "three CD O\n",
      "straight JJ O\n",
      "sessions NNS O\n",
      "of IN O\n",
      "losses NNS O\n",
      "took VBD O\n",
      "it PRP O\n",
      "to TO O\n",
      "the DT O\n",
      "lowest JJS O\n",
      "since IN O\n",
      "Nov.1 NNP O\n",
      "as IN O\n",
      "there EX O\n",
      "were VBD O\n",
      "still RB O\n",
      "considerable JJ O\n",
      "unresolved JJ O\n",
      "issues NNS O\n",
      "with IN O\n",
      "the DT O\n",
      "European NNP O\n",
      "Union NNP O\n",
      "over IN O\n",
      "Brexit NNP O\n",
      ", , O\n",
      "British NNP O\n",
      "Prime NNP O\n",
      "Minister NNP O\n",
      "Theresa NNP O\n",
      "May NNP O\n",
      "said VBD O\n",
      "on IN O\n",
      "Monday NNP O\n",
      ". . O\n"
     ]
    }
   ],
   "source": [
    "for word, pos, ner in iob_tagged:\n",
    "    print(word, pos, ner)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
